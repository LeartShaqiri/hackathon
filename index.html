<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Realistic AI Avatar with Gesture Tracking</title>
  <style>
    body { 
      margin: 0; 
      overflow: hidden; 
      background: #000; 
    }
    canvas { 
      display: block; 
    }
    #video { 
      position: absolute; 
      top: 10px; 
      left: 10px; 
      width: 320px; 
      height: 240px; 
    }
    #analysisCanvas { 
      display: none; 
    }
    #sidebar {
      position: fixed;
      top: 0;
      right: -250px;
      width: 250px;
      height: 100%;
      background: rgba(255, 255, 255, 0.2);
      backdrop-filter: blur(5px);
      transition: right 0.3s ease-in-out;
      padding: 20px;
      color: #fff;
      box-sizing: border-box;
    }
    #sidebar.open {
      right: 0;
    }
    #sidebar h2 {
      margin-top: 0;
    }
    #sidebar p {
      font-size: 16px;
    }
  </style>
</head>
<body>
  <video id="video" width="320" height="240" autoplay></video>
  <canvas id="analysisCanvas" width="320" height="240"></canvas>
  <div id="sidebar">
    <h2>Control Panel</h2>
    <p>Open your palm to show this sidebar, close your fist to hide it.</p>
  </div>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/three@0.134.0/examples/js/loaders/GLTFLoader.js"></script>
  <script>
    // Webcam setup
    const video = document.getElementById('video');
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => {
        video.srcObject = stream;
      })
      .catch(err => console.error("Error accessing webcam:", err));

    // Three.js setup
    const scene = new THREE.Scene();
    const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
    camera.position.z = 10;
    const renderer = new THREE.WebGLRenderer();
    renderer.setSize(window.innerWidth, window.innerHeight);
    document.body.appendChild(renderer.domElement);

    // Lighting for realistic appearance
    const ambientLight = new THREE.AmbientLight(0x404040);
    scene.add(ambientLight);
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.5);
    directionalLight.position.set(0, 1, 1);
    scene.add(directionalLight);

    // Load GLTF head model
    let head, jawBone;
    const loader = new THREE.GLTFLoader();
    loader.load(
      'https://raw.githubusercontent.com/mrdoob/three.js/dev/examples/models/gltf/LeePerrySmith/LeePerrySmith.glb',
      (gltf) => {
        head = gltf.scene;
        head.scale.set(1.5, 1.5, 1.5);
        head.position.set(0, 0, 0);
        scene.add(head);

        // Find jaw bone
        head.traverse((node) => {
          if (node.isBone && node.name.includes('jaw')) {
            jawBone = node;
          }
        });

        // Load skin texture
        const textureLoader = new THREE.TextureLoader();
        const skinTexture = textureLoader.load(
          'https://threejs.org/examples/textures/uv_grid_opengl.jpg'
        );
        head.traverse((node) => {
          if (node.isMesh) {
            node.material = new THREE.MeshStandardMaterial({
              map: skinTexture,
              color: 0xe0ac69, // Updated to requested skin color
              roughness: 0.8,
              metalness: 0.2
            });
          }
        });
      },
      undefined,
      (error) => console.error('Error loading GLTF:', error)
    );

    // Canvas for image processing
    const analysisCanvas = document.getElementById('analysisCanvas');
    const ctx = analysisCanvas.getContext('2d');
    let prevFrameData = null;
    let smoothedJawRotation = 0;
    let smoothedHeadX = 0;
    let smoothedHeadY = 0;
    let sidebarOpen = false;
    const sidebar = document.getElementById('sidebar');

    // Animation loop
    function animate() {
      requestAnimationFrame(animate);
      if (jawBone) {
        jawBone.rotation.x = THREE.MathUtils.lerp(jawBone.rotation.x, smoothedJawRotation, 0.2);
      }
      if (head) {
        head.rotation.y = THREE.MathUtils.lerp(head.rotation.y, smoothedHeadX, 0.2);
        head.rotation.x = THREE.MathUtils.lerp(head.rotation.x, smoothedHeadY, 0.2);
      }
      renderer.render(scene, camera);
    }
    animate();

    // Gesture detection with skin tone filtering
    function detectGestures() {
      ctx.drawImage(video, 0, 0, 320, 240);
      const frameData = ctx.getImageData(0, 0, 320, 240).data;

      if (prevFrameData) {
        // Mouth region
        let mouthDiff = 0;
        let mouthPixelCount = 0;
        const mouthX = 140, mouthY = 180, mouthW = 40, mouthH = 40;
        for (let y = mouthY; y < mouthY + mouthH; y++) {
          for (let x = mouthX; x < mouthX + mouthW; x++) {
            const i = (y * 320 + x) * 4;
            const r = frameData[i], g = frameData[i + 1], b = frameData[i + 2];
            if (r > 100 && r < 255 && g > 50 && g < 220 && b > 50 && b < 200 && r > g && r > b) {
              const rDiff = Math.abs(frameData[i] - prevFrameData[i]);
              const gDiff = Math.abs(frameData[i + 1] - prevFrameData[i + 1]);
              const bDiff = Math.abs(frameData[i + 2] - prevFrameData[i + 2]);
              mouthDiff += (rDiff + gDiff + bDiff) / 3;
              mouthPixelCount++;
            }
          }
        }
        mouthDiff = mouthPixelCount > 0 ? mouthDiff / mouthPixelCount : 0;
        smoothedJawRotation = THREE.MathUtils.lerp(
          smoothedJawRotation,
          THREE.MathUtils.clamp(mouthDiff / 80, 0, 0.4),
          0.3
        );

        // Head movement
        let headDiffX = 0, headDiffY = 0;
        let headPixelCount = 0;
        const headW = 120, headH = 120, headX = 100, headY = 60;
        for (let y = headY; y < headY + headH; y++) {
          for (let x = headX; x < headX + headW; x++) {
            const i = (y * 320 + x) * 4;
            const r = frameData[i], g = frameData[i + 1], b = frameData[i + 2];
            if (r > 100 && r < 255 && g > 50 && g < 220 && b > 50 && b < 200 && r > g && r > b) {
              const rDiff = frameData[i] - prevFrameData[i];
              const gDiff = frameData[i + 1] - prevFrameData[i + 1];
              const bDiff = frameData[i + 2] - prevFrameData[i + 2];
              const diff = (rDiff + gDiff + bDiff) / 3;
              headDiffX += (x - (headX + headW / 2)) * diff;
              headDiffY += (y - (headY + headH / 2)) * diff;
              headPixelCount++;
            }
          }
        }
        headDiffX = headPixelCount > 0 ? headDiffX / headPixelCount : 0;
        headDiffY = headPixelCount > 0 ? headDiffY / headPixelCount : 0;
        smoothedHeadX = THREE.MathUtils.lerp(smoothedHeadX, headDiffX / 400, 0.3);
        smoothedHeadY = THREE.MathUtils.lerp(smoothedHeadY, headDiffY / 400, 0.3);

        // Palm/fist detection
        let handDiff = 0;
        let handPixelCount = 0;
        const handX = 220, handY = 100, handW = 80, handH = 80; // Focus on right side for hand
        for (let y = handY; y < handY + handH; y++) {
          for (let x = handX; x < handX + handW; x++) {
            const i = (y * 320 + x) * 4;
            const r = frameData[i], g = frameData[i + 1], b = frameData[i + 2];
            if (r > 100 && r < 255 && g > 50 && g < 220 && b > 50 && b < 200 && r > g && r > b) {
              const rDiff = Math.abs(frameData[i] - prevFrameData[i]);
              const gDiff = Math.abs(frameData[i + 1] - prevFrameData[i + 1]);
              const bDiff = Math.abs(frameData[i + 2] - prevFrameData[i + 2]);
              handDiff += (rDiff + gDiff + bDiff) / 3;
              handPixelCount++;
            }
          }
        }
        handDiff = handPixelCount > 0 ? handDiff / handPixelCount : 0;

        // Toggle sidebar based on hand state
        const handThreshold = 20; // Adjusted for sensitivity
        if (handDiff > handThreshold && !sidebarOpen) { // Open palm: high variation
          sidebar.classList.add('open');
          sidebarOpen = true;
        } else if (handDiff < handThreshold && sidebarOpen) { // Fist: low variation
          sidebar.classList.remove('open');
          sidebarOpen = false;
        }
      }

      prevFrameData = frameData.slice();
    }

    // Process frames every 100ms
    video.addEventListener('play', () => {
      setInterval(detectGestures, 100);
    });
  </script>
</body>
</html>